{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOakdXG8ANRVkSGFhgpJC2i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Configs iniciais"],"metadata":{"id":"RAUk2byX4aBg"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"floMnTZ70rNN","executionInfo":{"status":"ok","timestamp":1758976185260,"user_tz":180,"elapsed":44768,"user":{"displayName":"Eduardo Medeiros","userId":"10594247742830776987"}},"outputId":"4e5830da-0e5e-44ac-96a8-cf6a27e332c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/tcc-modelo/tcc-demand-forecasting\n","TensorFlow: 2.19.0 | GPUs disponíveis: 1\n","DATA_DIR: /content/drive/MyDrive/tcc-modelo/data\n"]}],"source":["# === 0) Ajustes\n","GITHUB_USER = \"edumcm\"\n","REPO_NAME   = \"tcc-demand-forecasting\"\n","REPO_URL    = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n","\n","# === 1) Montar Drive ===\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# === 2) Definir caminhos ===\n","import os, pathlib, random, numpy as np, textwrap, shutil\n","\n","DRIVE_BASE = \"/content/drive/MyDrive/tcc-modelo\"\n","REPO_DIR   = f\"{DRIVE_BASE}/{REPO_NAME}\"\n","TMP_CLONE  = f\"/content/{REPO_NAME}\"\n","\n","pathlib.Path(DRIVE_BASE).mkdir(parents=True, exist_ok=True)\n","\n","# === 3) Garantir repo no Drive ===\n","if os.path.exists(REPO_DIR):\n","    # Já existe no Drive -> NÃO dar pull automático\n","    %cd {REPO_DIR}\n","    BRANCH = \"main\"  # ajuste se for 'master'\n","    # (Opcional) só avisa se o remoto avançou\n","    !git fetch -q origin\n","    ahead_behind = !git rev-list --left-right --count HEAD...origin/{BRANCH}\n","    if ahead_behind:\n","        ahead, behind = map(int, ahead_behind[0].split())\n","        if behind > 0:\n","            print(f\"Atenção: o remoto está {behind} commit(s) à frente. \"\n","                  \"Como o fluxo é só push, ignore ou faça pull manualmente se quiser.\")\n","else:\n","    # Não existe em lugar nenhum -> clonar direto no Drive\n","    %cd {DRIVE_BASE}\n","    !git clone {REPO_URL} {REPO_NAME}\n","    %cd {REPO_DIR}\n","\n","# === 4) Instalar dependências ===\n","%pip install -q -r requirements.txt\n","\n","# === 5) Configurar caminhos de dados/saídas (FORA do repo) ===\n","os.environ[\"DATA_DIR\"]      = \"/content/drive/MyDrive/tcc-modelo/data\"\n","os.environ[\"ARTIFACTS_DIR\"] = \"/content/drive/MyDrive/tcc-modelo/artifacts\"\n","os.environ[\"REPORTS_DIR\"]   = \"/content/drive/MyDrive/tcc-modelo/reports\"\n","for d in [os.environ[\"DATA_DIR\"], os.environ[\"ARTIFACTS_DIR\"], os.environ[\"REPORTS_DIR\"]]:\n","    os.makedirs(d, exist_ok=True)\n","\n","# === 6) Seeds e threads ===\n","SEED = 42\n","np.random.seed(SEED); random.seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n","os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n","os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n","\n","# === 7) Conferir GPU ===\n","import tensorflow as tf\n","print(\"TensorFlow:\", tf.__version__, \"| GPUs disponíveis:\", len(tf.config.list_physical_devices('GPU')))\n","print(\"DATA_DIR:\", os.environ[\"DATA_DIR\"])\n"]},{"cell_type":"markdown","source":["## configs yaml"],"metadata":{"id":"ZfSGk2ZeX4Mu"}},{"cell_type":"code","source":["import os, yaml, datetime, pathlib, json, sys\n","\n","PROJECT_ROOT = REPO_DIR\n","SRC_DIR = f\"{PROJECT_ROOT}/src\"\n","os.makedirs(SRC_DIR, exist_ok=True)\n","if SRC_DIR not in sys.path: sys.path.append(SRC_DIR)\n","\n","CONFIG_DIR = f\"{PROJECT_ROOT}/configs\"\n","os.makedirs(CONFIG_DIR, exist_ok=True)\n","\n","# 1) data.yaml\n","data_cfg = {\n","  \"paths\": {\n","    \"data_dir\": os.environ[\"DATA_DIR\"],\n","    \"artifacts_dir\": os.environ[\"ARTIFACTS_DIR\"],\n","    \"reports_dir\": os.environ[\"REPORTS_DIR\"]\n","  },\n","  \"datasets\": {\n","    \"olist\": {\n","      \"raw_dir\": f'{os.environ[\"DATA_DIR\"]}/raw',\n","      \"interim_dir\": f'{os.environ[\"DATA_DIR\"]}/interim',\n","      \"processed_dir\": f'{os.environ[\"DATA_DIR\"]}/processed'\n","    }\n","  },\n","  \"timezone\": \"America/Fortaleza\",\n","  \"date_format\": \"%Y-%m-%d\"\n","}\n","\n","# 2) cv.yaml (backtest)\n","cv_cfg = {\n","  \"strategy\": \"expanding_window\",\n","  \"horizons\": [7, 28],\n","  \"n_folds\": 6,\n","  \"gap_days\": 2,\n","  \"stride\": 7,\n","  \"group_col\": \"sku_id\",         # ajustar pós análise exploratória\n","  \"time_col\": \"order_purchase_timestamp\"\n","}\n","\n","# 3) features.yaml\n","feat_cfg = {\n","  \"target\": \"qty\",               # ajustar pós análise exploratória\n","  \"id_col\": \"sku_id\",\n","  \"time_col\": \"order_purchase_timestamp\",\n","  \"calendar\": [\"dow\",\"dom\",\"week\",\"month\",\"is_holiday\",\"bf_flag\"],\n","  \"lags\": [1, 7, 28],\n","  \"rollings\": [\n","    {\"lag\":1, \"window\":7, \"fn\":\"mean\"},\n","    {\"lag\":1, \"window\":28, \"fn\":\"mean\"},\n","    {\"lag\":1, \"window\":7, \"fn\":\"std\"}\n","  ],\n","  \"price_features\": [\"price_rel_sku\", \"price_rel_cat\"],   # ajustar pós análise exploratória\n","  \"leakage_guard\": True\n","}\n","\n","for name, cfg in [(\"data.yaml\", data_cfg), (\"cv.yaml\", cv_cfg), (\"features.yaml\", feat_cfg)]:\n","    p = f\"{CONFIG_DIR}/{name}\"\n","    if not os.path.exists(p):\n","        with open(p, \"w\") as f:\n","            yaml.safe_dump(cfg, f, sort_keys=False)\n","        print(\"Criado:\", p)\n"],"metadata":{"id":"tV31TiXDFwtG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## git ignore"],"metadata":{"id":"gAyV-xh7X7HS"}},{"cell_type":"code","source":["gi = f\"{PROJECT_ROOT}/.gitignore\"\n","lines = [\n","    \"\\n# Local/colab\\n.ipynb_checkpoints/\\n*.ipynb_meta.json\\n\",\n","    \"# Environments / caches\\n__pycache__/\\n*.pyc\\n\",\n","    \"# Data & outputs (mantidos fora do repo, mas por via das dúvidas)\\n/data/\\n/artifacts/\\n/reports/\\n\",\n","]\n","if os.path.exists(gi):\n","    with open(gi,\"a\") as f: f.writelines(lines)\n","    print(\"Atualizado .gitignore\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjE5mSxFWPSB","executionInfo":{"status":"ok","timestamp":1758666940321,"user_tz":180,"elapsed":820,"user":{"displayName":"Eduardo Medeiros","userId":"10594247742830776987"}},"outputId":"0c27039c-d467-490d-cba8-1002a4849821"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Atualizado .gitignore\n"]}]},{"cell_type":"markdown","source":["## snapshot de ambiente"],"metadata":{"id":"ivOTzxNlX9Xw"}},{"cell_type":"code","source":["snap_dir = f'{os.environ[\"ARTIFACTS_DIR\"]}/config_snapshots'\n","os.makedirs(snap_dir, exist_ok=True)\n","ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","!pip freeze > \"{snap_dir}/requirements-{ts}.txt\"\n","print(\"Snapshot salvo em:\", f\"{snap_dir}/requirements-{ts}.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYiQxDaqYBfV","executionInfo":{"status":"ok","timestamp":1758666942551,"user_tz":180,"elapsed":2226,"user":{"displayName":"Eduardo Medeiros","userId":"10594247742830776987"}},"outputId":"f10038e6-5987-4611-e1db-f30afb91b74d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Snapshot salvo em: /content/drive/MyDrive/tcc-modelo/artifacts/config_snapshots/requirements-20250923-223540.txt\n"]}]},{"cell_type":"markdown","source":["## seed hard + logging enxuto"],"metadata":{"id":"iV8TE_ByaVkH"}},{"cell_type":"code","source":["import logging, random, numpy as np, os, tensorflow as tf\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n","    datefmt=\"%H:%M:%S\"\n",")\n","\n","def fix_seeds(seed=42):\n","    random.seed(seed); np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    # Opcional: tentar determinismo (pode reduzir performance)\n","    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n","\n","fix_seeds(42)"],"metadata":{"id":"NMDULTbnaW53"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## criando um loader.py"],"metadata":{"id":"FkqCjRQ8RoVE"}},{"cell_type":"code","source":["%%writefile src/data/loader.py\n","import os\n","import glob\n","import pandas as pd\n","import yaml\n","\n","def load_dataset(cfg_path: str, dataset: str = \"olist\", stage: str = \"raw\") -> dict:\n","    \"\"\"\n","    Lê todos os CSVs de um dataset em um stage (raw, interim, processed).\n","    Retorna um dicionário {nome_arquivo: DataFrame}.\n","    \"\"\"\n","    with open(cfg_path, \"r\") as f:\n","        data_cfg = yaml.safe_load(f)\n","\n","    base_dir = data_cfg[\"datasets\"][dataset][f\"{stage}_dir\"]\n","    csv_files = glob.glob(os.path.join(base_dir, \"*.csv\"))\n","    dataframes = {os.path.basename(f): pd.read_csv(f) for f in csv_files}\n","    return dataframes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31XKH1cDIul8","executionInfo":{"status":"ok","timestamp":1758976213671,"user_tz":180,"elapsed":137,"user":{"displayName":"Eduardo Medeiros","userId":"10594247742830776987"}},"outputId":"1bcf27ab-5b6f-4292-fd67-51cdbaab5c81"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing src/data/loader.py\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lev86Ct-JXkn"},"execution_count":null,"outputs":[]}]}