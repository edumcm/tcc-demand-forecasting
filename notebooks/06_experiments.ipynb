{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEORJvvUi8Ph"
   },
   "source": [
    "## importações e configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16893,
     "status": "ok",
     "timestamp": 1763974901405,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "9ujaWA6PsrwF",
    "outputId": "5902f15d-c6ea-4930-e8c4-2a0c43f5255c"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y prophet cmdstanpy pystan\n",
    "!pip install -U prophet cmdstanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14720,
     "status": "ok",
     "timestamp": 1763974916127,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "dPdnRhChiz4l"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# modelos\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763974916159,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "OZGxxc2QAiJ8"
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26045,
     "status": "ok",
     "timestamp": 1763974942204,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "skq74utyjDKQ",
    "outputId": "f6c31555-2ca6-4657-85a3-e13c3d054a9f"
   },
   "outputs": [],
   "source": [
    "# Caminho raiz do projeto\n",
    "PROJ = Path(\"/content/drive/MyDrive/tcc-modelo/tcc-demand-forecasting\")\n",
    "\n",
    "# monta o drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Garante que o PROJECT_DIR está no sys.path\n",
    "if str(PROJ) not in sys.path:\n",
    "    sys.path.append(str(PROJ))\n",
    "\n",
    "print(\"Repositório ativo em:\", PROJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1763975003416,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "zozQ1nCbk6XM"
   },
   "outputs": [],
   "source": [
    "from src.evaluations.models_metrics import calculate_metrics, compare_models\n",
    "\n",
    "interim_dir = PROJ / \"data\" / \"interim\"\n",
    "output_name_imputed = \"olist_weekly_agg_withlags_imputed_2.parquet\"\n",
    "df_path = interim_dir / output_name_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1763974946857,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "2Z8cSL-NlV6o"
   },
   "outputs": [],
   "source": [
    "# Colunas do seu dataset\n",
    "date_col    = \"order_week\"   # mesma coluna para carimbar previsões\n",
    "target_col  = \"sales_qty\"    # alvo\n",
    "id_col      = \"id\"   # opcional\n",
    "\n",
    "# Períodos\n",
    "train_start     = pd.Timestamp(\"2017-04-01\")\n",
    "first_train_end = pd.Timestamp(\"2018-03-18\")\n",
    "test_start      = pd.Timestamp(\"2018-03-19\")\n",
    "test_end        = pd.Timestamp(\"2018-07-31\")\n",
    "\n",
    "# Janela de rolling (ex.: blocos de 1 semana)\n",
    "step = pd.Timedelta(days=7)  # (gap após cutoff, janela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1WhkOLMk1V8"
   },
   "source": [
    "## definição do df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsXOR6nyne02"
   },
   "source": [
    "### meu df sem filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1763974993563,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "baCtnsNN1YJL"
   },
   "outputs": [],
   "source": [
    "output_name_imputed = \"olist_weekly_agg_withlags_imputed.parquet\"\n",
    "df_path_all = interim_dir / output_name_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1763974995166,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "o1EBEJH31iSF"
   },
   "outputs": [],
   "source": [
    "meu_df_all = pd.read_parquet(df_path_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1763975059488,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "eg-vZcxHGz3H",
    "outputId": "5b2ee6c2-10e0-4b7b-c587-a61507381fbd"
   },
   "outputs": [],
   "source": [
    "meu_df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyAE-Q5_Hm0n"
   },
   "source": [
    "### meu df\n",
    "- já está filtrado o top7 sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVH3JTZu-c9A"
   },
   "outputs": [],
   "source": [
    "# fazer um teste com exatamente o mesmo dataframe utilizado por Feras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1850,
     "status": "ok",
     "timestamp": 1763975012949,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "8vRoR_K0k7ui"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1763814380245,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "vrGeboWmZpsB"
   },
   "outputs": [],
   "source": [
    "df = df[(df[date_col]>= train_start) & (df[date_col]<= test_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1763750521097,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "R1XVIc9vpGYU"
   },
   "outputs": [],
   "source": [
    "df['id'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1763750521103,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "Ol858dBtlqdS",
    "outputId": "0b9e7d66-7263-4fc3-a0c1-c6b48b57c16a"
   },
   "outputs": [],
   "source": [
    "deciles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "df['order_week'].describe(percentiles=deciles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cywItIGHqCo"
   },
   "source": [
    "### df feras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6689,
     "status": "ok",
     "timestamp": 1763819078538,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "PYeEYxxaHsOg",
    "outputId": "51fbc1ce-2a2d-471c-b6a6-fe90fb38982d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Carregar todos os CSVs RAW do Olist usando seu loader\n",
    "from src.data.loader import load_dataset\n",
    "\n",
    "cfg_path = \"/content/drive/MyDrive/tcc-modelo/tcc-demand-forecasting/configs/data.yaml\"\n",
    "dfs = load_dataset(str(cfg_path), dataset=\"olist\", stage=\"raw\")\n",
    "\n",
    "customers      = dfs[\"olist_customers_dataset.csv\"]\n",
    "products       = dfs[\"olist_products_dataset.csv\"]\n",
    "orders         = dfs[\"olist_orders_dataset.csv\"]\n",
    "order_items    = dfs[\"olist_order_items_dataset.csv\"]\n",
    "order_payments = dfs[\"olist_order_payments_dataset.csv\"]\n",
    "pc_name_trans  = dfs[\"product_category_name_translation.csv\"]\n",
    "\n",
    "# --- 2. Traduzir nomes de categoria para inglês (igual ao repo original) ---\n",
    "pc_map = pc_name_trans.set_index(\"product_category_name\")[\"product_category_name_english\"].to_dict()\n",
    "products[\"product_category_name\"] = products[\"product_category_name\"].map(pc_map)\n",
    "\n",
    "# --- 3. Replicar os merges principais do projeto original ---\n",
    "sales_order = orders.merge(customers, on=\"customer_id\", how=\"inner\")\n",
    "sales_order_item = order_items.merge(sales_order, on=\"order_id\", how=\"left\")\n",
    "sales_order_full = sales_order_item.merge(products, on=\"product_id\", how=\"inner\")\n",
    "sales_with_payments = sales_order_full.merge(order_payments, on=\"order_id\", how=\"inner\")\n",
    "\n",
    "# --- 4. Tratar datas e índice de tempo ---\n",
    "sales_with_payments[\"order_approved_at\"] = pd.to_datetime(\n",
    "    sales_with_payments[\"order_approved_at\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# filtro de sp\n",
    "#sales_with_payments = sales_with_payments[sales_with_payments['customer_state'] == 'SP']\n",
    "\n",
    "# remover linhas sem data, senão o .resample quebra\n",
    "sales_with_payments = sales_with_payments.dropna(subset=[\"order_approved_at\"])\n",
    "\n",
    "# definir índice de tempo\n",
    "sales_with_payments = sales_with_payments.set_index(\"order_approved_at\")\n",
    "\n",
    "# --- 5. Agregar por semana e categoria (mesmo conceito do projeto original) ---\n",
    "group_freq = \"W\"\n",
    "\n",
    "df_olist_weekly = (\n",
    "    sales_with_payments\n",
    "      .groupby(\"product_category_name\")\n",
    "      .resample(group_freq)[\"payment_value\"]\n",
    "      .count()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# renomear colunas para o formato usado no Prophet\n",
    "#df_olist_weekly = df_olist_weekly.rename(\n",
    "#    columns={\n",
    "#        \"order_approved_at\": \"ds\",\n",
    "#        \"payment_value\": \"y\"\n",
    "#    }\n",
    "#)\n",
    "\n",
    "# garantir ordenação\n",
    "df_olist_weekly = df_olist_weekly.sort_values([\"product_category_name\", \"order_approved_at\"]).reset_index(drop=True)\n",
    "\n",
    "df_olist_weekly.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHmBzxcm-7w9"
   },
   "source": [
    "## lista de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1763975171662,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "4T9i8qqN90k4"
   },
   "outputs": [],
   "source": [
    "desconsiderar = [ 'approval_time_hours_mean_co',\n",
    " 'approval_time_hours_mean_ne',\n",
    " 'approval_time_hours_mean_n',\n",
    " 'approval_time_hours_mean_se',\n",
    " 'approval_time_hours_mean_s',\n",
    " 'delivery_diff_estimated_mean_co',\n",
    " 'delivery_diff_estimated_mean_ne',\n",
    " 'delivery_diff_estimated_mean_n',\n",
    " 'delivery_diff_estimated_mean_se',\n",
    " 'delivery_diff_estimated_mean_s',\n",
    " 'est_delivery_lead_days_mean_co',\n",
    " 'est_delivery_lead_days_mean_ne',\n",
    " 'est_delivery_lead_days_mean_n',\n",
    " 'est_delivery_lead_days_mean_se',\n",
    " 'est_delivery_lead_days_mean_s',\n",
    " 'delivery_diff_estimated_weighted',\n",
    " 'est_delivery_lead_days_weighted',\n",
    " 'approval_time_hours_weighted',\n",
    " 'customer_regions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1763975171709,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "GlYDmHVRkFuB"
   },
   "outputs": [],
   "source": [
    "# Garante tipo datetime\n",
    "df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "# Seleciona features \"completas\" (a função já exclui y/id/date por padrão)\n",
    "#features = feature_set_all(df.columns.tolist())\n",
    "#features = [c for c in features if c not in desconsiderar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1763975171715,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "smbR0GhAv3-L"
   },
   "outputs": [],
   "source": [
    "selected_features = ['sales_qty_roll8_mean',\n",
    " 'sales_qty_lag1',\n",
    " 'sales_qty_roll4_mean',\n",
    " 'sales_qty_lag2',\n",
    " 'sales_qty_lag4',\n",
    " 'sales_qty_lag8',\n",
    " 'sales_qty_roll8_std',\n",
    " 'sales_qty_roll4_std',\n",
    " 'approval_time_hours_weighted_roll8_std',\n",
    " 'price_var_m4_vs_prev4_mean_roll8_std',\n",
    " 'est_delivery_lead_days_weighted_roll8_std',\n",
    " 'approval_time_hours_weighted_roll4_std',\n",
    " 'est_delivery_lead_days_weighted',\n",
    " 'delivery_diff_estimated_weighted',\n",
    " 'est_delivery_lead_days_weighted_roll4_std',\n",
    " 'price_var_m4_vs_prev4_mean_roll4_std',\n",
    " 'price_var_w1_point_mean_roll8_std',\n",
    " 'price_var_w1_point_mean_roll4_std',\n",
    " 'price_var_w1_smooth_mean_roll8_std',\n",
    " 'approval_time_hours_weighted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5BQWCqjjIv7"
   },
   "source": [
    "## funcoes uteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1763975184223,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "bUAhrRHsjKWT"
   },
   "outputs": [],
   "source": [
    "# ---------- Esquemas de treinamento ----------\n",
    "def split_rolling(\n",
    "    df: pd.DataFrame,\n",
    "    date_col: str,\n",
    "    first_train_end: pd.Timestamp,\n",
    "    step: pd.Timedelta,\n",
    ") -> List[Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Expanding window simples: a cada iteração,\n",
    "    - treino = tudo até current_end\n",
    "    - validação = (current_end, current_end + step]\n",
    "    Avança current_end em 'step' a cada loop.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    current_end = first_train_end\n",
    "\n",
    "    while True:\n",
    "        val_end = current_end + step\n",
    "\n",
    "        train = df[df[date_col] <= current_end].copy()\n",
    "        valid = df[(df[date_col] > current_end) & (df[date_col] <= val_end)].copy()\n",
    "\n",
    "        if valid.empty:\n",
    "            break\n",
    "\n",
    "        pairs.append((train, valid))\n",
    "        current_end = val_end  # avança a janela\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# ---------- Gera dataframes pela categoria do produto ----------\n",
    "def split_by_category(df: pd.DataFrame, category_col: str):\n",
    "  \"\"\"\n",
    "  Retorna um dicionário de dataframes, sendo um para cada categoria de produto\n",
    "  \"\"\"\n",
    "  dfs = {}\n",
    "  for col in df[category_col].unique():\n",
    "    dfs[col] = df[df[category_col] == col].copy()\n",
    "  return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1763975186693,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "wNXAssFLYInk"
   },
   "outputs": [],
   "source": [
    " # ---------- gráfico predito x real ----------\n",
    "def plot_real_pred(real: np.array, pred: np.array):\n",
    "  \"\"\"\n",
    "  Plota gráfico de linhas com valores reais vs o predito\n",
    "  \"\"\"\n",
    "\n",
    "  plt.plot(y_true_cat[:50], label=\"true\")\n",
    "  plt.plot(y_pred_cat[:50], label=\"pred\")\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1763975187862,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "X8SIvoYRF3UF"
   },
   "outputs": [],
   "source": [
    " # ---------- HPO estático ----------\n",
    "def run_lgbm_hpo_static(\n",
    "    df: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    date_col: str,\n",
    "    target_col: str,\n",
    "    first_train_end: pd.Timestamp,\n",
    "    n_splits: int = 3,\n",
    "    n_iter: int = 30,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Faz HPO estático (uma vez só) usando todo o período até first_train_end.\n",
    "    Retorna best_params para serem reutilizados nos backtests por categoria.\n",
    "    \"\"\"\n",
    "    # Usa apenas dados até o fim do treino estático\n",
    "    df_train = df[df[date_col] <= first_train_end].sort_values(date_col).copy()\n",
    "\n",
    "    X = df_train[features]\n",
    "    y = df_train[target_col]\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    # Espaço de busca reduzido para não explodir o tempo\n",
    "    param = {\n",
    "        \"num_leaves\": [31, 63, 127],\n",
    "        \"max_depth\": [-1, 8, 12],\n",
    "        \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "        \"n_estimators\": [200, 400, 800],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.8, 1.0],\n",
    "        \"min_child_samples\": [10, 20, 30],\n",
    "        \"reg_alpha\": [0.0, 0.1],\n",
    "        \"reg_lambda\": [0.0, 0.1],\n",
    "    }\n",
    "\n",
    "    base = LGBMRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    searcher = RandomizedSearchCV(\n",
    "        estimator=base,\n",
    "        param_distributions=param,\n",
    "        n_iter=n_iter,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    searcher.fit(X, y)\n",
    "\n",
    "    best_params = searcher.best_params_\n",
    "    print(\">>> Best params (HPO estático):\")\n",
    "    print(best_params)\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x37gVsKq3AC9"
   },
   "source": [
    "## modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQK_vmWL3CFe"
   },
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ura9kOPcaNkl"
   },
   "source": [
    "#### função do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1763975220696,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "BZO7Io_dGp26"
   },
   "outputs": [],
   "source": [
    "def fit_predict_lgbm_fixed(\n",
    "    train: pd.DataFrame,\n",
    "    valid: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    date_col: str,\n",
    "    target_col: str,\n",
    "    best_params: Dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Treina e prediz com LGBM usando hiperparâmetros fixos (best_params).\n",
    "    \"\"\"\n",
    "    train_sorted = train.sort_values(date_col)\n",
    "    valid_sorted = valid.sort_values(date_col)\n",
    "\n",
    "    X_tr = train_sorted[features]\n",
    "    y_tr = train_sorted[target_col]\n",
    "    X_va = valid_sorted[features]\n",
    "    y_va = valid_sorted[target_col]\n",
    "\n",
    "    mdl = lgb.LGBMRegressor(\n",
    "        random_state=42,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    mdl.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric=\"smape\",\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100, verbose=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preds = mdl.predict(X_va)\n",
    "    return preds, mdl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anD_gqX5hCJ4"
   },
   "source": [
    "#### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1763975223318,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "VAHNoDiw13lI"
   },
   "outputs": [],
   "source": [
    "df_hpo = df[df[date_col] <= first_train_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1763975223349,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "x3pC2mON14G0"
   },
   "outputs": [],
   "source": [
    "df_hpo_all = meu_df_all[meu_df_all[date_col] <= first_train_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 519882,
     "status": "ok",
     "timestamp": 1763975743255,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "wotnERhYhLXX",
    "outputId": "f43c517c-291f-4597-b896-193272a0134d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- roda HPO uma vez só ----\n",
    "best_params = run_lgbm_hpo_static(\n",
    "    df=df_hpo_all,\n",
    "    features=selected_features,\n",
    "    date_col=date_col,\n",
    "    target_col=target_col,\n",
    "    first_train_end=first_train_end,\n",
    "    n_splits=3,\n",
    "    n_iter=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKyzq75TGuDy"
   },
   "source": [
    "#### teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1763814795553,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "LMpN5vDahcac"
   },
   "outputs": [],
   "source": [
    "# Períodos  iguais ao de feras\n",
    "train_start     = pd.Timestamp(\"2017-01-01\")\n",
    "first_train_end = pd.Timestamp(\"2018-01-06\")\n",
    "test_start      = pd.Timestamp(\"2018-01-07\")\n",
    "test_end        = pd.Timestamp(\"2018-08-12\")\n",
    "\n",
    "step = pd.Timedelta(days=7)  # (gap após cutoff, janela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10532,
     "status": "ok",
     "timestamp": 1763814807731,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "-Vn2nFoPG7Oq",
    "outputId": "ccd44692-934b-4291-cb33-106f798c64a0"
   },
   "outputs": [],
   "source": [
    "results_by_cat = {}\n",
    "\n",
    "for cat, df_cat in df.groupby(\"product_category_name\"):\n",
    "    print(f\"\\n######## Categoria: {cat} ########\")\n",
    "\n",
    "    # Gera splits rolling só para essa categoria\n",
    "    pairs = split_rolling(\n",
    "        df=df_cat,\n",
    "        date_col=date_col,\n",
    "        first_train_end=first_train_end,\n",
    "        step=step,\n",
    "    )\n",
    "\n",
    "    y_true_cat = []\n",
    "    y_pred_cat = []\n",
    "    date = []\n",
    "\n",
    "    for i, (train_i, valid_i) in enumerate(pairs):\n",
    "        # limita a janela de validação ao período de teste global\n",
    "        valid_i = valid_i[\n",
    "            (valid_i[date_col] >= test_start) &\n",
    "            (valid_i[date_col] <= test_end)\n",
    "        ]\n",
    "        if valid_i.empty:\n",
    "            continue\n",
    "\n",
    "        preds_i, _ = fit_predict_lgbm_fixed(\n",
    "            train=train_i,\n",
    "            valid=valid_i,\n",
    "            features=selected_features,\n",
    "            date_col=date_col,\n",
    "            target_col=target_col,\n",
    "            best_params=best_params,\n",
    "        )\n",
    "\n",
    "        y_true_cat.extend(valid_i[target_col].tolist())\n",
    "        y_pred_cat.extend(preds_i.tolist())\n",
    "        date.extend(valid_i[date_col].tolist())\n",
    "\n",
    "    if len(y_true_cat) == 0:\n",
    "        print(f\"  >> Sem janelas válidas no período de teste para categoria {cat}, pulando.\")\n",
    "        continue\n",
    "\n",
    "    y_true_cat = np.array(y_true_cat)\n",
    "    y_pred_cat = np.array(y_pred_cat)\n",
    "\n",
    "    results_by_cat[cat] = {\n",
    "        \"y_true\": y_true_cat,\n",
    "        \"y_pred\": y_pred_cat,\n",
    "        \"date\": date\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1763814637715,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "aX-WSjV2Zl6I",
    "outputId": "d0bcbbd3-4129-4024-bc85-2002cd2d3168"
   },
   "outputs": [],
   "source": [
    "plot_real_pred(y_true_cat, y_pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1763814807833,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "CRZrKqviqBg3",
    "outputId": "18c3817b-5ff5-4443-9319-3df0a4f835af"
   },
   "outputs": [],
   "source": [
    "# dataframe com os resultados de cada categoria\n",
    "y_true_cat = []\n",
    "y_pred_cat = []\n",
    "date = []\n",
    "categorias = []\n",
    "\n",
    "for cat, results in results_by_cat.items():\n",
    "    y_true_cat.extend(results['y_true'])\n",
    "    y_pred_cat.extend(results['y_pred'])\n",
    "    date.extend(results['date'])\n",
    "    categorias.extend([cat] * len(results['y_true']))\n",
    "\n",
    "df_all = pd.DataFrame({\n",
    "    'y_true': y_true_cat,\n",
    "    'y_pred': y_pred_cat,\n",
    "    'date': date,\n",
    "    'categoria': categorias\n",
    "})\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1763814818963,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "PZTBkvtTufRH",
    "outputId": "dfaf27a9-3e0b-4d8c-aa7f-014a44bec62d"
   },
   "outputs": [],
   "source": [
    "# dataframe com as metricas de cada categoria e geral\n",
    "\n",
    "metrics_all = calculate_metrics(df_all, 'y_true', 'y_pred').to_dict()\n",
    "metrics_all['categoria'] = 'all'\n",
    "metrics_all = pd.DataFrame([metrics_all])\n",
    "\n",
    "for categoria in df_all['categoria'].unique():\n",
    "  metrics_cat = calculate_metrics(df_all[df_all['categoria'] == categoria], 'y_true', 'y_pred').to_dict()\n",
    "  metrics_cat['categoria'] = categoria\n",
    "  metrics_cat = pd.DataFrame([metrics_cat])\n",
    "  metrics_all = pd.concat([metrics_all, metrics_cat])\n",
    "\n",
    "metrics_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI956qBr2COc"
   },
   "source": [
    "#### teste com todas categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1763975790057,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "Iq2bsbbTHfMI"
   },
   "outputs": [],
   "source": [
    "# Períodos  iguais ao de feras\n",
    "train_start     = pd.Timestamp(\"2017-01-01\")\n",
    "first_train_end = pd.Timestamp(\"2018-01-06\")\n",
    "test_start      = pd.Timestamp(\"2018-01-07\")\n",
    "test_end        = pd.Timestamp(\"2018-08-12\")\n",
    "\n",
    "step = pd.Timedelta(days=7)  # (gap após cutoff, janela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26945,
     "status": "ok",
     "timestamp": 1763975922460,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "WbBTCg6mJRIt",
    "outputId": "33dfbfcd-7e8d-4005-d56e-ac0b8f3b89c6"
   },
   "outputs": [],
   "source": [
    "results_by_cat = {}\n",
    "\n",
    "for cat, df_cat in meu_df_all.groupby(\"product_category_name\"):\n",
    "    print(f\"\\n######## Categoria: {cat} ########\")\n",
    "\n",
    "    # Gera splits rolling só para essa categoria\n",
    "    pairs = split_rolling(\n",
    "        df=df_cat,\n",
    "        date_col=date_col,\n",
    "        first_train_end=first_train_end,\n",
    "        step=step,\n",
    "    )\n",
    "\n",
    "    y_true_cat = []\n",
    "    y_pred_cat = []\n",
    "    date = []\n",
    "\n",
    "    for i, (train_i, valid_i) in enumerate(pairs):\n",
    "        # limita a janela de validação ao período de teste global\n",
    "        valid_i = valid_i[\n",
    "            (valid_i[date_col] >= test_start) &\n",
    "            (valid_i[date_col] <= test_end)\n",
    "        ]\n",
    "        if valid_i.empty:\n",
    "            continue\n",
    "\n",
    "        preds_i, _ = fit_predict_lgbm_fixed(\n",
    "            train=train_i,\n",
    "            valid=valid_i,\n",
    "            features=selected_features,\n",
    "            date_col=date_col,\n",
    "            target_col=target_col,\n",
    "            best_params=best_params,\n",
    "        )\n",
    "\n",
    "        y_true_cat.extend(valid_i[target_col].tolist())\n",
    "        y_pred_cat.extend(preds_i.tolist())\n",
    "        date.extend(valid_i[date_col].tolist())\n",
    "\n",
    "    if len(y_true_cat) == 0:\n",
    "        print(f\"  >> Sem janelas válidas no período de teste para categoria {cat}, pulando.\")\n",
    "        continue\n",
    "\n",
    "    y_true_cat = np.array(y_true_cat)\n",
    "    y_pred_cat = np.array(y_pred_cat)\n",
    "\n",
    "    results_by_cat[cat] = {\n",
    "        \"y_true\": y_true_cat,\n",
    "        \"y_pred\": y_pred_cat,\n",
    "        \"date\": date\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1763975930622,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "OCx-L6nOJSTX",
    "outputId": "f4b36033-395f-4a32-e409-6de03bc56c63"
   },
   "outputs": [],
   "source": [
    "# dataframe com os resultados de cada categoria\n",
    "y_true_cat = []\n",
    "y_pred_cat = []\n",
    "date = []\n",
    "categorias = []\n",
    "\n",
    "for cat, results in results_by_cat.items():\n",
    "    y_true_cat.extend(results['y_true'])\n",
    "    y_pred_cat.extend(results['y_pred'])\n",
    "    date.extend(results['date'])\n",
    "    categorias.extend([cat] * len(results['y_true']))\n",
    "\n",
    "df_all = pd.DataFrame({\n",
    "    'y_true': y_true_cat,\n",
    "    'y_pred': y_pred_cat,\n",
    "    'date': date,\n",
    "    'categoria': categorias\n",
    "})\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 145,
     "status": "ok",
     "timestamp": 1763975941715,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "6tL_s7wNJSI3",
    "outputId": "410c85d8-5789-4937-eaa5-e34d54a194c8"
   },
   "outputs": [],
   "source": [
    "# dataframe com as metricas de cada categoria e geral\n",
    "\n",
    "metrics_all = calculate_metrics(df_all, 'y_true', 'y_pred').to_dict()\n",
    "metrics_all['categoria'] = 'all'\n",
    "metrics_all = pd.DataFrame([metrics_all])\n",
    "\n",
    "for categoria in df_all['categoria'].unique():\n",
    "  metrics_cat = calculate_metrics(df_all[df_all['categoria'] == categoria], 'y_true', 'y_pred').to_dict()\n",
    "  metrics_cat['categoria'] = categoria\n",
    "  metrics_cat = pd.DataFrame([metrics_cat])\n",
    "  metrics_all = pd.concat([metrics_all, metrics_cat])\n",
    "\n",
    "metrics_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE-uUUvX3A34"
   },
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpX3asYRy2pn"
   },
   "source": [
    "#### funcao do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1763807030494,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "Gpx3BajgoJKB"
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "def fit_predict_prophet_fixed(\n",
    "    train: pd.DataFrame,\n",
    "    valid: pd.DataFrame,\n",
    "    date_col: str,\n",
    "    target_col: str,\n",
    "    features: Optional[List[str]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Treina e prediz com Prophet usando hiperparâmetros fixos (params).\n",
    "\n",
    "    - date_col: coluna de datas\n",
    "    - target_col: coluna target (ex.: 'sales_qty')\n",
    "    - features: lista de colunas usadas como regressoras externas (podem ser [] ou None)\n",
    "    - params: dicionário com hiperparâmetros do Prophet\n",
    "      (ex.: {'seasonality_mode': 'additive', 'changepoint_prior_scale': 0.05, ...})\n",
    "    \"\"\"\n",
    "    # Garante ordem temporal\n",
    "    train_sorted = train.sort_values(date_col).copy()\n",
    "    valid_sorted = valid.sort_values(date_col).copy()\n",
    "\n",
    "    if features is None:\n",
    "        features = []\n",
    "\n",
    "    # Monta dataframes no formato esperado pelo Prophet (ds, y, + regressors)\n",
    "    df_tr = train_sorted[[date_col, target_col] + features].rename(\n",
    "        columns={date_col: \"ds\", target_col: \"y\"}\n",
    "    )\n",
    "    df_va = valid_sorted[[date_col] + features].rename(\n",
    "        columns={date_col: \"ds\"}\n",
    "    )\n",
    "\n",
    "    # Instancia o modelo com os hiperparâmetros informados\n",
    "    mdl = Prophet(weekly_seasonality=True,\n",
    "                            yearly_seasonality=True,\n",
    "                            daily_seasonality=False)\n",
    "\n",
    "    # Adiciona regressoras externas, se houver\n",
    "    for reg in features:\n",
    "        mdl.add_regressor(reg)\n",
    "\n",
    "    # Treina\n",
    "    mdl.fit(df_tr)\n",
    "\n",
    "    # Faz previsão para o período de validação\n",
    "    forecast = mdl.predict(df_va)\n",
    "\n",
    "    # Prophet devolve várias colunas; usamos yhat como predição\n",
    "    preds = forecast[\"yhat\"].values\n",
    "\n",
    "    return preds, mdl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IxvS_B8506B"
   },
   "source": [
    "#### definindo parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1763753834658,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "eK7aui3853X-"
   },
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"seasonality_mode\": [\"additive\", \"multiplicative\"],\n",
    "    \"changepoint_prior_scale\": [0.001, 0.01, 0.05, 0.1],\n",
    "    \"seasonality_prior_scale\": [1.0, 5.0, 10.0],\n",
    "    \"weekly_seasonality\": [True, False],\n",
    "    \"yearly_seasonality\": [False, True],\n",
    "    \"daily_seasonality\": [False],  # fixo\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1763753835739,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "VuMHDP7A6De5"
   },
   "outputs": [],
   "source": [
    "def random_search_prophet_metrics(\n",
    "    train: pd.DataFrame,\n",
    "    valid: pd.DataFrame,\n",
    "    date_col: str,\n",
    "    target_col: str,\n",
    "    features: Optional[List[str]],\n",
    "    param_space: Dict[str, List[Any]],\n",
    "    n_iter: int = 20,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Faz random search simples de hiperparâmetros do Prophet e retorna\n",
    "    um DataFrame com métricas + parâmetros de cada tentativa.\n",
    "\n",
    "    - param_space: dict com lista de valores possíveis para cada hiperparâmetro\n",
    "      ex.: {\"changepoint_prior_scale\": [0.01, 0.05], \"seasonality_mode\": [\"additive\", \"multiplicative\"], ...}\n",
    "    - n_iter: número de amostras aleatórias de combinações de parâmetros\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    results = []\n",
    "\n",
    "    # y_true da base de validação (df completo, sem separar categorias)\n",
    "    y_true = valid[target_col].values\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Sorteia uma combinação de parâmetros\n",
    "        params = {\n",
    "            name: rng.choice(values)\n",
    "            for name, values in param_space.items()\n",
    "        }\n",
    "\n",
    "        # Treina e prediz\n",
    "        preds, _ = fit_predict_prophet_fixed(\n",
    "            train=train,\n",
    "            valid=valid,\n",
    "            date_col=date_col,\n",
    "            target_col=target_col,\n",
    "            features=features,\n",
    "            params=params,\n",
    "        )\n",
    "\n",
    "        # Monta df de avaliação compatível com calculate_metrics()\n",
    "        df_eval = valid[[date_col, target_col]].copy()\n",
    "        df_eval = df_eval.rename(columns={target_col: \"y_true\"})\n",
    "        df_eval[\"y_pred\"] = preds\n",
    "\n",
    "        # Calcula métricas\n",
    "        metrics_dict = calculate_metrics(df_eval, \"y_true\", \"y_pred\").to_dict()\n",
    "\n",
    "        # Adiciona info de parâmetros e iteração\n",
    "        metrics_dict.update(params)\n",
    "        metrics_dict[\"iter\"] = i + 1\n",
    "\n",
    "        results.append(metrics_dict)\n",
    "\n",
    "    # DataFrame com uma linha por combinação de parâmetros\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1763753822414,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "HrOwWN8i6dnv"
   },
   "outputs": [],
   "source": [
    "train_static = df[df[date_col] <= first_train_end].sort_values(date_col).copy()\n",
    "test_static = df[df[date_col] > first_train_end].sort_values(date_col).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8930,
     "status": "ok",
     "timestamp": 1763754053823,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "RHiYYgRE6YcW"
   },
   "outputs": [],
   "source": [
    "results_df = random_search_prophet_metrics(\n",
    "    train=train_static,      # df de treino completo\n",
    "    valid=test_static,       # df de validação completo\n",
    "    date_col=date_col,  # exemplo\n",
    "    target_col=target_col,\n",
    "    features=None,           # ou lista de regressoras, se quiser testar\n",
    "    param_space=param_space,\n",
    "    n_iter=80,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1763754055661,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "X4Aiiqee7wRg",
    "outputId": "fe3b7e4a-fa33-45d1-ae58-b85a3cbac6c0"
   },
   "outputs": [],
   "source": [
    "results_df.sort_values(\"wape\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD8fTHAFqmOj"
   },
   "source": [
    "#### teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6871,
     "status": "ok",
     "timestamp": 1763754701991,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "aA2dP0EFqv2u",
    "outputId": "2b144bdd-8c00-4ef1-e551-56f0f1525d67"
   },
   "outputs": [],
   "source": [
    "results_by_cat = {}\n",
    "\n",
    "for cat, df_cat in df.groupby(\"product_category_name\"):\n",
    "    print(f\"\\n######## Categoria: {cat} ########\")\n",
    "\n",
    "    # Gera splits rolling só para essa categoria\n",
    "    pairs = split_rolling(\n",
    "        df=df_cat,\n",
    "        date_col=date_col,\n",
    "        first_train_end=first_train_end,\n",
    "        step=step,\n",
    "    )\n",
    "\n",
    "    y_true_cat = []\n",
    "    y_pred_cat = []\n",
    "    date = []\n",
    "\n",
    "    for i, (train_i, valid_i) in enumerate(pairs):\n",
    "        # limita a janela de validação ao período de teste global\n",
    "        valid_i = valid_i[\n",
    "            (valid_i[date_col] >= test_start) &\n",
    "            (valid_i[date_col] <= test_end)\n",
    "        ]\n",
    "        if valid_i.empty:\n",
    "            continue\n",
    "\n",
    "        preds_i, _ = fit_predict_prophet_fixed(\n",
    "            train=train_i,\n",
    "            valid=valid_i,\n",
    "            features=[],\n",
    "            date_col=date_col,\n",
    "            target_col=target_col\n",
    "        )\n",
    "\n",
    "        y_true_cat.extend(valid_i[target_col].tolist())\n",
    "        y_pred_cat.extend(preds_i.tolist())\n",
    "        date.extend(valid_i[date_col].tolist())\n",
    "\n",
    "    if len(y_true_cat) == 0:\n",
    "        print(f\"  >> Sem janelas válidas no período de teste para categoria {cat}, pulando.\")\n",
    "        continue\n",
    "\n",
    "    y_true_cat = np.array(y_true_cat)\n",
    "    y_pred_cat = np.array(y_pred_cat)\n",
    "\n",
    "    results_by_cat[cat] = {\n",
    "        \"y_true\": y_true_cat,\n",
    "        \"y_pred\": y_pred_cat,\n",
    "        \"date\": date\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1763754702067,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "6wMf1Httux-W"
   },
   "outputs": [],
   "source": [
    "# dataframe com os resultados de cada categoria\n",
    "y_true_cat = []\n",
    "y_pred_cat = []\n",
    "date = []\n",
    "categorias = []\n",
    "\n",
    "for cat, results in results_by_cat.items():\n",
    "    y_true_cat.extend(results['y_true'])\n",
    "    y_pred_cat.extend(results['y_pred'])\n",
    "    date.extend(results['date'])\n",
    "    categorias.extend([cat] * len(results['y_true']))\n",
    "\n",
    "df_all = pd.DataFrame({\n",
    "    'y_true': y_true_cat,\n",
    "    'y_pred': y_pred_cat,\n",
    "    'date': date,\n",
    "    'categoria': categorias\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1763754714299,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "e5fq05q-u61b",
    "outputId": "fc128c42-f7e2-489c-9501-97f927260e13"
   },
   "outputs": [],
   "source": [
    "# dataframe com as metricas de cada categoria e geral\n",
    "\n",
    "metrics_all = calculate_metrics(df_all, 'y_true', 'y_pred').to_dict()\n",
    "metrics_all['categoria'] = 'all'\n",
    "metrics_all = pd.DataFrame([metrics_all])\n",
    "\n",
    "for categoria in df_all['categoria'].unique():\n",
    "  metrics_cat = calculate_metrics(df_all[df_all['categoria'] == categoria], 'y_true', 'y_pred').to_dict()\n",
    "  metrics_cat['categoria'] = categoria\n",
    "  metrics_cat = pd.DataFrame([metrics_cat])\n",
    "  metrics_all = pd.concat([metrics_all, metrics_cat])\n",
    "\n",
    "metrics_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9-nPwUqAd_9"
   },
   "source": [
    "#### recriando o teste de feras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 87797,
     "status": "ok",
     "timestamp": 1763806294585,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "IZa0g1HxAf_8",
    "outputId": "a19aad15-7f75-42a1-accc-4d2a32fbdd15"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from prophet import Prophet  # ou: from fbprophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1) Definições de datas e categorias (params.yml)\n",
    "# -------------------------------------------------------\n",
    "experiment_dates = {\n",
    "    \"train_start\": \"2017-01-01\",\n",
    "    \"test_start\": \"2018-01-07\",\n",
    "    \"test_end\":   \"2018-08-12\",\n",
    "}\n",
    "\n",
    "product_categories = [\n",
    "    \"bed_bath_table\",\n",
    "    \"health_beauty\",\n",
    "    \"sports_leisure\",\n",
    "    \"furniture_decor\",\n",
    "    \"housewares\",\n",
    "    \"watches_gifts\",\n",
    "    \"telephony\",\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2) Função make_dates (igual ao utils.py do repo)\n",
    "# -------------------------------------------------------\n",
    "def make_dates(experiment_dates: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cria folds de datas com {train, valid, test}, com janelas de 4 semanas.\n",
    "    Mesma lógica do src/utils.py do projeto original.\n",
    "    \"\"\"\n",
    "    date_ranges = []\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        train_start_0 = pd.to_datetime(experiment_dates[\"train_start\"])\n",
    "        test_start_0  = pd.to_datetime(experiment_dates[\"test_start\"])\n",
    "        test_end_0    = pd.to_datetime(experiment_dates[\"test_end\"])\n",
    "\n",
    "        # deslocamento do fold em blocos de 4 semanas\n",
    "        offset = timedelta(weeks=4 * i)\n",
    "\n",
    "        train_start = train_start_0 + offset\n",
    "        # train_end = test_start + offset - 1 semana - 4 semanas\n",
    "        train_end   = test_start_0 + offset - timedelta(weeks=1) - timedelta(weeks=4)\n",
    "\n",
    "        valid_start = test_start_0 + offset - timedelta(weeks=4)\n",
    "        valid_end   = test_start_0 + offset - timedelta(weeks=1)\n",
    "\n",
    "        test_start  = test_start_0 + offset\n",
    "        # test_end = test_start_0 + (4*i + 4) semanas - 1 semana\n",
    "        test_end    = test_start_0 + timedelta(weeks=(4 * i + 4)) - timedelta(weeks=1)\n",
    "\n",
    "        dates_ = {\n",
    "            \"train_start\": train_start,\n",
    "            \"train_end\":   train_end,\n",
    "            \"valid_start\": valid_start,\n",
    "            \"valid_end\":   valid_end,\n",
    "            \"test_start\":  test_start,\n",
    "            \"test_end\":    test_end,\n",
    "        }\n",
    "        date_ranges.append(dates_)\n",
    "\n",
    "        if test_end >= test_end_0:\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    return pd.DataFrame(date_ranges)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3) Métricas (baseadas em src/metrics.py, sem mlflow)\n",
    "# -------------------------------------------------------\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    # versão do projeto: soma 1 para evitar divisão por 0\n",
    "    y_true = np.array(y_true) + 1\n",
    "    y_pred = np.array(y_pred) + 1\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def weighted_mean_absolute_error(test, predict):\n",
    "    # versão do projeto: soma 1, pondera pelo valor de teste\n",
    "    test = np.array(test) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    fenmu = max(test)\n",
    "    rs = []\n",
    "    for i in range(len(test)):\n",
    "        if test[i] == 0:\n",
    "            p = 1\n",
    "        else:\n",
    "            p = test[i]\n",
    "        fenzi = (abs(test[i] - predict[i])) * p * p\n",
    "        rs.append(float(fenzi) / fenmu)\n",
    "    return np.mean(rs)\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    wape = weighted_mean_absolute_error(y_true, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2_metric = r2_score(y_true, y_pred)\n",
    "    mape_metric = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"wape\": wape,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\":   r2_metric,\n",
    "        \"mape\": mape_metric,\n",
    "        \"mae\":  mae,\n",
    "    }\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4) Geração dos folds de datas\n",
    "# -------------------------------------------------------\n",
    "date_ranges = make_dates(experiment_dates)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5) Garantir que merged_data está no formato certo\n",
    "#    (ajuste aqui se seu df tiver outro nome)\n",
    "# -------------------------------------------------------\n",
    "# merged_data deve ter colunas:\n",
    "#   - 'order_approved_at' (datetime semanal)\n",
    "#   - 'product_category_name'\n",
    "#   - 'payment_value'\n",
    "# Se ainda não for datetime:\n",
    "df_olist_weekly[\"order_approved_at\"] = pd.to_datetime(df_olist_weekly[\"order_approved_at\"])\n",
    "\n",
    "# opcional: garantir ordenação global\n",
    "merged_data = df_olist_weekly.sort_values([\"product_category_name\", \"order_approved_at\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6) Loop principal do experimento Prophet (sem mlflow)\n",
    "# -------------------------------------------------------\n",
    "output_dir = \"artifacts/predictions_prophet_original\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_results = []  # para guardar métricas por categoria\n",
    "\n",
    "for prod_cat in product_categories:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Processando categoria: {prod_cat}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    start_timer = time()\n",
    "    all_predictions = []\n",
    "\n",
    "    # loop sobre os folds de tempo\n",
    "    for row in date_ranges.itertuples(index=False):\n",
    "        train_start, train_end, valid_start, valid_end, test_start, test_end = (\n",
    "            row.train_start,\n",
    "            row.train_end,\n",
    "            row.valid_start,\n",
    "            row.valid_end,\n",
    "            row.test_start,\n",
    "            row.test_end,\n",
    "        )\n",
    "\n",
    "        print(f\"  Faixa: {train_start.date()} até {test_end.date()}\")\n",
    "\n",
    "        # Treino = [train_start, valid_end]\n",
    "        train_mask = (\n",
    "            (merged_data[\"order_approved_at\"] >= train_start)\n",
    "            & (merged_data[\"order_approved_at\"] <= valid_end)\n",
    "            & (merged_data[\"product_category_name\"] == prod_cat)\n",
    "        )\n",
    "        train_x = merged_data.loc[train_mask, [\"order_approved_at\", \"payment_value\"]]\n",
    "\n",
    "        # Teste = [test_start, test_end]\n",
    "        test_mask = (\n",
    "            (merged_data[\"order_approved_at\"] >= test_start)\n",
    "            & (merged_data[\"order_approved_at\"] <= test_end)\n",
    "            & (merged_data[\"product_category_name\"] == prod_cat)\n",
    "        )\n",
    "        test_y = merged_data.loc[test_mask, [\"order_approved_at\", \"payment_value\"]]\n",
    "\n",
    "        # renomear colunas para Prophet\n",
    "        train_x = train_x.rename(columns={\"order_approved_at\": \"ds\", \"payment_value\": \"y\"})\n",
    "        test_y  = test_y.rename(columns={\"order_approved_at\": \"ds\", \"payment_value\": \"y\"})\n",
    "\n",
    "        # garantir ordenação temporal\n",
    "        train_x = train_x.sort_values(\"ds\").reset_index(drop=True)\n",
    "        test_y  = test_y.sort_values(\"ds\").reset_index(drop=True)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Rolling dentro do período de teste (igual ao código original)\n",
    "        # --------------------------------------------------\n",
    "        predictions = []\n",
    "        for i in range(test_y.shape[0]):\n",
    "            # modelo Prophet novo a cada passo\n",
    "            model = Prophet(\n",
    "                weekly_seasonality=True,\n",
    "                yearly_seasonality=True,\n",
    "                daily_seasonality=False,\n",
    "            )\n",
    "            model.add_country_holidays(country_name=\"BR\")\n",
    "\n",
    "            # concatena treino \"fixo\" com parte já observada do teste\n",
    "            # (train_x.iloc[i:] vem do código original, apesar de estranho)\n",
    "            df_fit = pd.concat([train_x.iloc[i:], test_y.iloc[:i]]).reset_index(drop=True)\n",
    "\n",
    "            model.fit(df_fit)\n",
    "\n",
    "            # previsão 1 passo à frente (7 dias, pois série é semanal)\n",
    "            future = model.make_future_dataframe(periods=1, freq=\"7D\")\n",
    "            fcst = model.predict(future)[\"yhat\"].iloc[-1]\n",
    "            predictions.append(fcst)\n",
    "\n",
    "        all_predictions.extend(predictions)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Após todos os folds, calcular métricas no período de teste global\n",
    "    # -------------------------------------------------------\n",
    "    global_test_mask = (\n",
    "        (merged_data[\"product_category_name\"] == prod_cat)\n",
    "        & (merged_data[\"order_approved_at\"] >= pd.to_datetime(experiment_dates[\"test_start\"]))\n",
    "        & (merged_data[\"order_approved_at\"] <= pd.to_datetime(experiment_dates[\"test_end\"]))\n",
    "    )\n",
    "\n",
    "    df_filtered = merged_data.loc[global_test_mask, [\"order_approved_at\", \"payment_value\"]].copy()\n",
    "    df_filtered = df_filtered.sort_values(\"order_approved_at\").reset_index(drop=True)\n",
    "\n",
    "    # garantir alinhamento: len(y_true) == len(all_predictions)\n",
    "    y_true = df_filtered[\"payment_value\"].values\n",
    "    y_pred = np.array(all_predictions[: len(y_true)])  # safety\n",
    "\n",
    "    metrics = get_metrics(y_true, y_pred)\n",
    "    duration_min = int((time() - start_timer) // 60)\n",
    "\n",
    "    print(f\"  Métricas para {prod_cat}: {metrics}\")\n",
    "    print(f\"  Tempo (min): {duration_min}\")\n",
    "\n",
    "    # salvar previsões em CSV (similar ao original)\n",
    "    save_data = pd.DataFrame(\n",
    "        {\n",
    "            \"y_true\": y_true,\n",
    "            \"preds\": y_pred,\n",
    "            \"dates\": df_filtered[\"order_approved_at\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fname = os.path.join(output_dir, f\"exp1_prophet_{prod_cat}.csv\")\n",
    "    save_data.to_csv(fname, index=False)\n",
    "\n",
    "    # acumular resultado geral\n",
    "    all_results.append(\n",
    "        {\n",
    "            \"product_category\": prod_cat,\n",
    "            \"time_min\": duration_min,\n",
    "            **metrics,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7) DataFrame consolidado de métricas por categoria\n",
    "# -------------------------------------------------------\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVDe_TOnD_eH"
   },
   "source": [
    "#### aplicando base de feras com meu pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pi0DwVyfEqsH"
   },
   "outputs": [],
   "source": [
    "experiment_dates = {\n",
    "    \"train_start\": \"2017-01-01\",\n",
    "    \"test_start\": \"2018-01-07\",\n",
    "    \"test_end\":   \"2018-08-12\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1763817148607,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "dgVXVnjsEgOf"
   },
   "outputs": [],
   "source": [
    "# Períodos  iguais ao de feras\n",
    "train_start     = pd.Timestamp(\"2017-01-01\")\n",
    "first_train_end = pd.Timestamp(\"2018-01-06\")\n",
    "test_start      = pd.Timestamp(\"2018-01-07\")\n",
    "test_end        = pd.Timestamp(\"2018-08-12\")\n",
    "\n",
    "step = pd.Timedelta(days=7)  # (gap após cutoff, janela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1763816387064,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "i_oK99dRgLdl"
   },
   "outputs": [],
   "source": [
    "# meus periodos\n",
    "train_start     = pd.Timestamp(\"2017-04-01\")\n",
    "first_train_end = pd.Timestamp(\"2018-03-18\")\n",
    "test_start      = pd.Timestamp(\"2018-03-19\")\n",
    "test_end        = pd.Timestamp(\"2018-07-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1763817152756,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "kup7UbY4GOkn"
   },
   "outputs": [],
   "source": [
    "product_categories = [\n",
    "    \"bed_bath_table\",\n",
    "    \"health_beauty\",\n",
    "    \"sports_leisure\",\n",
    "    \"furniture_decor\",\n",
    "    \"housewares\",\n",
    "    \"watches_gifts\",\n",
    "    \"telephony\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1763817155324,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "M-XxO9iRFeiV"
   },
   "outputs": [],
   "source": [
    "df_olist_weekly = df_olist_weekly.rename(columns={\"order_approved_at\": \"order_week\", \"payment_value\": \"sales_qty\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1763817156134,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "85MgtfwtGKU8"
   },
   "outputs": [],
   "source": [
    "df_olist_weekly = df_olist_weekly[df_olist_weekly['product_category_name'].isin(product_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107425,
     "status": "ok",
     "timestamp": 1763817265010,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "HD99zpZOEDCV",
    "outputId": "46c91981-56a4-4af8-c252-7f82888653ca"
   },
   "outputs": [],
   "source": [
    "results_by_cat = {}\n",
    "\n",
    "for cat, df_cat in df_olist_weekly.groupby(\"product_category_name\"):\n",
    "    print(f\"\\n######## Categoria: {cat} ########\")\n",
    "\n",
    "    # Gera splits rolling só para essa categoria\n",
    "    pairs = split_rolling(\n",
    "        df=df_cat,\n",
    "        date_col=date_col,\n",
    "        first_train_end=first_train_end,\n",
    "        step=step,\n",
    "    )\n",
    "\n",
    "    y_true_cat = []\n",
    "    y_pred_cat = []\n",
    "    date = []\n",
    "\n",
    "    for i, (train_i, valid_i) in enumerate(pairs):\n",
    "        # limita a janela de validação ao período de teste global\n",
    "        valid_i = valid_i[\n",
    "            (valid_i[date_col] >= test_start) &\n",
    "            (valid_i[date_col] <= test_end)\n",
    "        ]\n",
    "        if valid_i.empty:\n",
    "            continue\n",
    "\n",
    "        preds_i, _ = fit_predict_prophet_fixed(\n",
    "            train=train_i,\n",
    "            valid=valid_i,\n",
    "            features=[],\n",
    "            date_col=date_col,\n",
    "            target_col=target_col\n",
    "        )\n",
    "\n",
    "        y_true_cat.extend(valid_i[target_col].tolist())\n",
    "        y_pred_cat.extend(preds_i.tolist())\n",
    "        date.extend(valid_i[date_col].tolist())\n",
    "\n",
    "    if len(y_true_cat) == 0:\n",
    "        print(f\"  >> Sem janelas válidas no período de teste para categoria {cat}, pulando.\")\n",
    "        continue\n",
    "\n",
    "    y_true_cat = np.array(y_true_cat)\n",
    "    y_pred_cat = np.array(y_pred_cat)\n",
    "\n",
    "    results_by_cat[cat] = {\n",
    "        \"y_true\": y_true_cat,\n",
    "        \"y_pred\": y_pred_cat,\n",
    "        \"date\": date\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1763817265040,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "AxCmKuo3EJFm"
   },
   "outputs": [],
   "source": [
    "# dataframe com os resultados de cada categoria\n",
    "y_true_cat = []\n",
    "y_pred_cat = []\n",
    "date = []\n",
    "categorias = []\n",
    "\n",
    "for cat, results in results_by_cat.items():\n",
    "    y_true_cat.extend(results['y_true'])\n",
    "    y_pred_cat.extend(results['y_pred'])\n",
    "    date.extend(results['date'])\n",
    "    categorias.extend([cat] * len(results['y_true']))\n",
    "\n",
    "df_all = pd.DataFrame({\n",
    "    'y_true': y_true_cat,\n",
    "    'y_pred': y_pred_cat,\n",
    "    'date': date,\n",
    "    'categoria': categorias\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1763817265088,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "WbEujzm4ENWx",
    "outputId": "905e1de0-7bf0-4332-faf2-85004d449634"
   },
   "outputs": [],
   "source": [
    "# dataframe com as metricas de cada categoria e geral\n",
    "\n",
    "metrics_all = calculate_metrics(df_all, 'y_true', 'y_pred').to_dict()\n",
    "metrics_all['categoria'] = 'all'\n",
    "metrics_all = pd.DataFrame([metrics_all])\n",
    "\n",
    "for categoria in df_all['categoria'].unique():\n",
    "  metrics_cat = calculate_metrics(df_all[df_all['categoria'] == categoria], 'y_true', 'y_pred').to_dict()\n",
    "  metrics_cat['categoria'] = categoria\n",
    "  metrics_cat = pd.DataFrame([metrics_cat])\n",
    "  metrics_all = pd.concat([metrics_all, metrics_cat])\n",
    "\n",
    "metrics_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8J2lRqAt_8u"
   },
   "source": [
    "#### aplicando para o dataset inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763819078840,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "_6A8ziQDuFsi"
   },
   "outputs": [],
   "source": [
    "# Períodos  iguais ao de feras\n",
    "train_start     = pd.Timestamp(\"2017-01-01\")\n",
    "first_train_end = pd.Timestamp(\"2018-01-06\")\n",
    "test_start      = pd.Timestamp(\"2018-01-07\")\n",
    "test_end        = pd.Timestamp(\"2018-08-12\")\n",
    "\n",
    "step = pd.Timedelta(days=7)  # (gap após cutoff, janela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1763819080336,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "vNUmN2zZuVOH"
   },
   "outputs": [],
   "source": [
    "df_olist_weekly = df_olist_weekly.rename(columns={\"order_approved_at\": \"order_week\", \"payment_value\": \"sales_qty\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1763819113490,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "L49jYRodzGP-"
   },
   "outputs": [],
   "source": [
    "# agrupando por data, somando as vendas, sem categoria\n",
    "df_olist_weekly = df_olist_weekly.groupby('order_week')['sales_qty'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1763819125303,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "tufRDrWtzhgK",
    "outputId": "eb4119a4-e710-42ca-d5e9-4c69f97a12ee"
   },
   "outputs": [],
   "source": [
    "df_olist_weekly.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1763818605586,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "6PA9RNP5x32T"
   },
   "outputs": [],
   "source": [
    "x, y = pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1763818626870,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "gtTmhqQIyBWw",
    "outputId": "e8f80fc5-eab8-414f-e738-7ed0debbfa91"
   },
   "outputs": [],
   "source": [
    "x['product_category_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15660,
     "status": "ok",
     "timestamp": 1763819286244,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "EBmmHUJAugRQ"
   },
   "outputs": [],
   "source": [
    "pairs = split_rolling(\n",
    "    df=df_olist_weekly,\n",
    "    date_col=date_col,\n",
    "    first_train_end=first_train_end,\n",
    "    step=step,\n",
    ")\n",
    "\n",
    "y_true_cat = []\n",
    "y_pred_cat = []\n",
    "date = []\n",
    "\n",
    "for i, (train_i, valid_i) in enumerate(pairs):\n",
    "    # limita a janela de validação ao período de teste global\n",
    "    valid_i = valid_i[\n",
    "        (valid_i[date_col] >= test_start) &\n",
    "        (valid_i[date_col] <= test_end)\n",
    "    ]\n",
    "    if valid_i.empty:\n",
    "        continue\n",
    "\n",
    "    preds_i, _ = fit_predict_prophet_fixed(\n",
    "        train=train_i,\n",
    "        valid=valid_i,\n",
    "        features=[],\n",
    "        date_col=date_col,\n",
    "        target_col=target_col\n",
    "    )\n",
    "\n",
    "    y_true_cat.extend(valid_i[target_col].tolist())\n",
    "    y_pred_cat.extend(preds_i.tolist())\n",
    "    date.extend(valid_i[date_col].tolist())\n",
    "\n",
    "y_true_cat = np.array(y_true_cat)\n",
    "y_pred_cat = np.array(y_pred_cat)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"y_true\": y_true_cat,\n",
    "    \"y_pred\": y_pred_cat,\n",
    "    \"date\": date\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1763819304089,
     "user": {
      "displayName": "Eduardo Medeiros",
      "userId": "10594247742830776987"
     },
     "user_tz": 180
    },
    "id": "LRiWelORvKIk",
    "outputId": "1a2a57ea-59b1-435d-827d-dae3a9cbd905"
   },
   "outputs": [],
   "source": [
    "# dataframe com as metricas de cada categoria e geral\n",
    "\n",
    "metrics_all = calculate_metrics(results, 'y_true', 'y_pred').to_dict()\n",
    "metrics_all['categoria'] = 'all'\n",
    "metrics_all = pd.DataFrame([metrics_all])\n",
    "\n",
    "\n",
    "metrics_all"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPm/J30JVWPxfvzRoMXTOLb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
